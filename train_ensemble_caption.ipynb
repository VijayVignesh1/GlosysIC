{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Positional Encoder ##############\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len = 200, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = \\\n",
    "                math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                pe[pos, i + 1] = \\\n",
    "                math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    " \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Input is ( batch size, seqlength, d_model)\n",
    "        # Output is ( batch size, seqlength, d_model)\n",
    "        # pe is ( 1, seqlength, decdim)\n",
    "        # make embeddings relatively larger\n",
    "        x = x * math.sqrt(self.d_model)\n",
    "        #add constant to embedding\n",
    "        seq_len = x.size(1)\n",
    "        pe = Variable(self.pe[:,:seq_len], requires_grad=False)\n",
    "        if x.is_cuda:\n",
    "            pe.cuda()\n",
    "        x = x + pe\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Multi Head Attention #######\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, heads, d_model, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_model // heads\n",
    "        self.h = heads\n",
    "        \n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        \n",
    "        bs = q.size(0)\n",
    "        \n",
    "        # The Inputs are (BatchSize, SeqLength, d_model)\n",
    "        # perform linear operation and split into N heads\n",
    "        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n",
    "        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n",
    "        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n",
    "        \n",
    "        # transpose to get dimensions bs * N * sl * d_model\n",
    "        k = k.transpose(1,2)\n",
    "        q = q.transpose(1,2)\n",
    "        v = v.transpose(1,2)\n",
    "        \n",
    "\n",
    "        # calculate attention using function we will define next\n",
    "        scores = attention(q, k, v, self.d_k, mask, self.dropout)\n",
    "        # concatenate heads and put through final linear layer\n",
    "        concat = scores.transpose(1,2).contiguous()\\\n",
    "        .view(bs, -1, self.d_model)\n",
    "        output = self.out(concat)\n",
    "    \n",
    "        return output\n",
    "\n",
    "def attention(q, k, v, d_k, mask=None, dropout=None):\n",
    "    \n",
    "    scores = torch.matmul(q, k.transpose(-2, -1)) /  math.sqrt(d_k)\n",
    "    # scores is ( batch size,no of heads , seqlength, seqlenght)\n",
    "\n",
    "    if mask is not None:\n",
    "        mask = mask.unsqueeze(1)\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    \n",
    "    scores = F.softmax(scores, dim=-1)\n",
    "    \n",
    "    if dropout is not None:\n",
    "        scores = dropout(scores)\n",
    "        \n",
    "    output = torch.matmul(scores, v)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Embedder ######\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Embedder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "    def forward(self, x):\n",
    "        # Input is ( batch size, seqlength)\n",
    "        # Output is ( batch size, seqlength, d_model)\n",
    "        return self.embed(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Decoder #########\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import copy\n",
    "#from MultiHeadAttention import MultiHeadAttention\n",
    "#import PositionalEncoder\n",
    "#import Embedder\n",
    "#import FeedForward\n",
    "#import Norm\n",
    "\n",
    "def get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, N = 6, heads = 8, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.embed = Embedder(vocab_size, d_model)\n",
    "        self.pe = PositionalEncoder(d_model, dropout=dropout)\n",
    "        self.layers = get_clones(DecoderLayer(d_model, heads, dropout), N)\n",
    "        self.norm = Norm(d_model)\n",
    "        self.out=nn.Linear(d_model,vocab_size)\n",
    "    def forward(self, trg, e_outputs, trg_mask,caption_lengths):\n",
    "        caption_lengths, sort_ind=caption_lengths.squeeze(1).sort(dim=0, descending=True)\n",
    "        trg=trg[sort_ind]\n",
    "        e_outputs=e_outputs[sort_ind]\n",
    "        x = self.embed(trg)\n",
    "        x = self.pe(x)\n",
    "        for i in range(self.N):\n",
    "            x = self.layers[i](x, e_outputs, trg_mask)\n",
    "        y = self.norm(x)\n",
    "        return self.out(y), trg ,caption_lengths, sort_ind\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.norm_1 = Norm(d_model)\n",
    "        self.norm_2 = Norm(d_model)\n",
    "        self.norm_3 = Norm(d_model)\n",
    "        \n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        self.dropout_3 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.attn_1 = MultiHeadAttention(heads, d_model, dropout=dropout)\n",
    "        self.attn_2 = MultiHeadAttention(heads, d_model, dropout=dropout)\n",
    "        self.ff = FeedForward(d_model, dropout=dropout)\n",
    "\n",
    "    # Used for forward traversal from the decoder and the encoders final output\n",
    "    def forward(self, x, e_outputs, trg_mask):\n",
    "        # Input is (batch, seq length)\n",
    "        # Output is (batch, seq length, d_model)\n",
    "        x2 = self.norm_1(x)\n",
    "        x = x + self.dropout_1(self.attn_1(x2, x2, x2, trg_mask))\n",
    "        x2 = self.norm_2(x)\n",
    "        x = x + self.dropout_2(self.attn_2(x2, e_outputs, e_outputs))\n",
    "        x2 = self.norm_3(x)\n",
    "        x = x + self.dropout_3(self.ff(x2))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Feed Forward #######\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "# Feed Forward net work is used for traversing the inputs w.r.t hidden layers and is just a straight forward network\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=2048, dropout = 0.1):\n",
    "        super().__init__() \n",
    "    \n",
    "        # We set d_ff as a default to 2048\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Whatever Input is it just returns back the same\n",
    "        x = self.dropout(F.relu(self.linear_1(x)))\n",
    "        x = self.linear_2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Norm #######\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class Norm(nn.Module):\n",
    "    def __init__(self, d_model, eps = 1e-6):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.size = d_model\n",
    "        \n",
    "        # create two learnable parameters to calibrate normalisation\n",
    "        self.alpha = nn.Parameter(torch.ones(self.size))\n",
    "        self.bias = nn.Parameter(torch.zeros(self.size))\n",
    "        \n",
    "        self.eps = eps\n",
    "    \n",
    "    def forward(self, x):\n",
    "        norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) \\\n",
    "        / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n",
    "        return norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## utils ########\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import json\n",
    "import torch\n",
    "from scipy.misc import imresize\n",
    "#from imageio import imread\n",
    "#from PIL.Image import resize as imresize\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from random import seed, choice, sample\n",
    "\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "class tokenize(object):\n",
    "    \n",
    "    def __init__(self, lang):\n",
    "        self.nlp = spacy.load(lang)\n",
    "            \n",
    "    def tokenizer(self, sentence):\n",
    "        sentence = re.sub(\n",
    "        r\"[\\*\\\"â€œâ€\\n\\\\â€¦\\+\\-\\/\\=\\(\\)â€˜â€¢:\\[\\]\\|â€™\\!;]\", \" \", str(sentence))\n",
    "        sentence = re.sub(r\"[ ]+\", \" \", sentence)\n",
    "        sentence = re.sub(r\"\\!+\", \"!\", sentence)\n",
    "        sentence = re.sub(r\"\\,+\", \",\", sentence)\n",
    "        sentence = re.sub(r\"\\?+\", \"?\", sentence)\n",
    "        sentence = sentence.lower()\n",
    "        return [tok.text for tok in self.nlp.tokenizer(sentence) if tok.text != \" \"]\n",
    "\n",
    "\n",
    "def clip_gradient(optimizer, grad_clip):\n",
    "    \"\"\"\n",
    "    Clips gradients computed during backpropagation to avoid explosion of gradients.\n",
    "\n",
    "    :param optimizer: optimizer with the gradients to be clipped\n",
    "    :param grad_clip: clip value\n",
    "    \"\"\"\n",
    "    for group in optimizer.param_groups:\n",
    "        for param in group['params']:\n",
    "            if param.grad is not None:\n",
    "                param.grad.data.clamp_(-grad_clip, grad_clip)\n",
    "\n",
    "def save_checkpoint(data_name, epoch, epochs_since_improvement, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "                    bleu4, is_best):\n",
    "    \"\"\"\n",
    "    Saves model checkpoint.\n",
    "\n",
    "    :param data_name: base name of processed dataset\n",
    "    :param epoch: epoch number\n",
    "    :param epochs_since_improvement: number of epochs since last improvement in BLEU-4 score\n",
    "    :param encoder: encoder model\n",
    "    :param decoder: decoder model\n",
    "    :param encoder_optimizer: optimizer to update encoder's weights, if fine-tuning\n",
    "    :param decoder_optimizer: optimizer to update decoder's weights\n",
    "    :param bleu4: validation BLEU-4 score for this epoch\n",
    "    :param is_best: is this checkpoint the best so far?\n",
    "    \"\"\"\n",
    "    state = {'epoch': epoch,\n",
    "             'epochs_since_improvement': epochs_since_improvement,\n",
    "             'bleu-4': bleu4,\n",
    "             'encoder': encoder,\n",
    "             'decoder': decoder,\n",
    "             'encoder_optimizer': encoder_optimizer,\n",
    "             'decoder_optimizer': decoder_optimizer}\n",
    "    filename = 'checkpoint_' + data_name + '_resnet' + '.pth.tar'\n",
    "    torch.save(state, filename)\n",
    "    # If this checkpoint is the best so far, store a copy so it doesn't get overwritten by a worse checkpoint\n",
    "    if is_best:\n",
    "        torch.save(state, 'BEST_' + filename)\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"\n",
    "    Keeps track of most recent, average, sum, and count of a metric.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, shrink_factor):\n",
    "    \"\"\"\n",
    "    Shrinks learning rate by a specified factor.\n",
    "\n",
    "    :param optimizer: optimizer whose learning rate must be shrunk.\n",
    "    :param shrink_factor: factor in interval (0, 1) to multiply learning rate with.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\nDECAYING learning rate.\")\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = param_group['lr'] * shrink_factor\n",
    "    print(\"The new learning rate is %f\\n\" % (optimizer.param_groups[0]['lr'],))\n",
    "\n",
    "\n",
    "def accuracy(scores, targets, k):\n",
    "    \"\"\"\n",
    "    Computes top-k accuracy, from predicted and true labels.\n",
    "\n",
    "    :param scores: scores from the model\n",
    "    :param targets: true labels\n",
    "    :param k: k in top-k accuracy\n",
    "    :return: top-k accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = targets.size(0)\n",
    "    _, ind = scores.topk(k, 1, True, True)\n",
    "    correct = ind.eq(targets.view(-1, 1).expand_as(ind))\n",
    "    correct_total = correct.view(-1).float().sum()  # 0D tensor\n",
    "    return correct_total.item() * (100.0 / batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### encoder #######\n",
    "\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torch\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoded_image_size=14):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.enc_image_size = encoded_image_size\n",
    "\n",
    "        self.encoder_trans = nn.Linear(2048, 512) \n",
    "        \n",
    "        resnet = torchvision.models.resnet101(pretrained=True)  # pretrained ImageNet ResNet-101\n",
    "\n",
    "        # Remove linear and pool layers (since we're not doing classification)\n",
    "        modules = list(resnet.children())[:-2]\n",
    "        self.resnet = nn.Sequential(*modules)\n",
    "\n",
    "        # Resize image to fixed size to allow input images of variable size\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((encoded_image_size, encoded_image_size))\n",
    "\n",
    "        ####\n",
    "        \"\"\"\n",
    "        vgg=torchvision.models.vgg16(pretrained=True)\n",
    "        modules_vgg=list(vgg.features.children())[:-1]\n",
    "        self.vgg=nn.Sequential(*modules_vgg)\n",
    "        \"\"\"\n",
    "        ####\n",
    "        \n",
    "    def forward(self, images):\n",
    "        \"\"\"\n",
    "        Forward propagation.\n",
    "\n",
    "        :param images: images, a tensor of dimensions (batch_size, 3, image_size, image_size)\n",
    "        :return: encoded images\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            out = self.resnet(images)  # (batch_size, 2048, image_size/32, image_size/32)\n",
    "            out = self.adaptive_pool(out)  # (batch_size, 2048, encoded_image_size, encoded_image_size)\n",
    "            out = out.permute(0, 2, 3, 1)  # (batch_size, encoded_image_size, encoded_image_size, 2048)\n",
    "            batch_size=out.size(0)\n",
    "            out = out.view(batch_size, -1, 2048)\n",
    "            out = self.encoder_trans(out)\n",
    "            #print(out.size())\n",
    "            \n",
    "            \"\"\"\n",
    "            #### VGG ####\n",
    "            out_vgg=self.vgg(images)\n",
    "            out_vgg = self.adaptive_pool(out_vgg)\n",
    "            #print(\"asda\")\n",
    "            #print(out_vgg.shape)\n",
    "            out_vgg=out_vgg.permute(0,2,3,1)\n",
    "            batch_size=out_vgg.size(0)\n",
    "            out_vgg=out_vgg.view(batch_size,-1,512)\n",
    "            #print(\"vgg\")\n",
    "            #print(out_vgg.shape)\n",
    "            object_mean=torch.mean(torch.stack([out,out_vgg],dim=0).float(),dim=0)\n",
    "            #print(object_mean)\n",
    "            #print(out)\n",
    "            \"\"\"\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### load datasets ##########\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import h5py\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "class CaptionDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset class to be used in a PyTorch DataLoader to create batches.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_folder, data_name,data_type='None', transform=None):\n",
    "        \"\"\"\n",
    "        :param data_folder: folder where data files are stored\n",
    "        :param data_name: base name of processed datasets\n",
    "        :param split: split, one of 'TRAIN', 'VAL', or 'TEST'\n",
    "        :param transform: image transform pipeline\n",
    "        \"\"\"\n",
    "\n",
    "        # Open hdf5 file where images are stored\n",
    "        add=''\n",
    "        if data_type=='VAL':\n",
    "            add='_VAL' \n",
    "        self.h = h5py.File(os.path.join(data_folder, 'IMAGES' + data_name + add + '.hdf5'), 'r')\n",
    "        self.imgs = self.h['images']\n",
    "        self.split = data_type\n",
    "        # Captions per image\n",
    "        self.cpi = self.h.attrs['captions_per_image']\n",
    "\n",
    "        # Load encoded captions (completely into memory)\n",
    "        with open(os.path.join(data_folder, 'CAPTIONS' + data_name + add + '.json'), 'r') as j:\n",
    "            self.captions = json.load(j)\n",
    "\n",
    "        # Load caption lengths (completely into memory)\n",
    "        with open(os.path.join(data_folder, 'CAPLENS' + data_name + add + '.json'), 'r') as j:\n",
    "            self.caplens = json.load(j)\n",
    "\n",
    "        # PyTorch transformation pipeline for the image (normalizing, etc.)\n",
    "        self.transform = transform\n",
    "\n",
    "        # Total number of datapoints\n",
    "        self.dataset_size = len(self.captions)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # Remember, the Nth caption corresponds to the (N // captions_per_image)th image\n",
    "        img = torch.FloatTensor(self.imgs[i // self.cpi] / 255.)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        caption = torch.LongTensor(self.captions[i])\n",
    "\n",
    "        caplen = torch.LongTensor([self.caplens[i]])\n",
    "\n",
    "        if self.split is 'TRAIN':\n",
    "            return img, caption, caplen\n",
    "        else:\n",
    "            # For validation of testing, also return all 'captions_per_image' captions to find BLEU-4 score\n",
    "            all_captions = torch.LongTensor(\n",
    "                self.captions[((i // self.cpi) * self.cpi):(((i // self.cpi) * self.cpi) + self.cpi)])\n",
    "            return img, caption, caplen, all_captions\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### train ######\n",
    "import time\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "\n",
    "\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "# Data parameters\n",
    "data_folder = ''  # folder with data files saved by create_input_files.py\n",
    "data_name = '_GLOSYS'  # base name shared by data files\n",
    "\n",
    "# Model parameters\n",
    "emb_dim = 512  # dimension of word embeddings\n",
    "attention_dim = 512  # dimension of attention linear layers\n",
    "decoder_dim = 512  # dimension of decoder RNN\n",
    "dropout = 0.5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # sets device for model and PyTorch tensors\n",
    "cudnn.benchmark = True  # set to true only if inputs to model are fixed size; otherwise lot of computational overhead\n",
    "\n",
    "# Training parameters\n",
    "start_epoch = 0\n",
    "epochs = 4  # number of epochs to train for (if early stopping is not triggered)\n",
    "epochs_since_improvement = 1  # keeps track of number of epochs since there's been an improvement in validation BLEU\n",
    "batch_size = 50\n",
    "workers = 0  # for data-loading; right now, only 1 works with h5py\n",
    "encoder_lr = 1e-4  # learning rate for encoder if fine-tuning\n",
    "decoder_lr = 4e-4  # learning rate for decoder\n",
    "grad_clip = 5.  # clip gradients at an absolute value of\n",
    "alpha_c = 1.  # regularization parameter for 'doubly stochastic attention', as in the paper\n",
    "best_bleu4 = 0.  # BLEU-4 score right now\n",
    "print_freq = 100  # print training/validation stats every __ batches\n",
    "fine_tune_encoder = False  # fine-tune encoder?\n",
    "checkpoint = 'checkpoint__GLOSYS_resnet.pth.tar'  # path to checkpoint, None if none\n",
    "#checkpoint = None\n",
    "def nopeak_mask(size):\n",
    "    np_mask = np.triu(np.ones((1, size, size)),\n",
    "    k=1).astype('uint8')\n",
    "    np_mask =  Variable(torch.from_numpy(np_mask) == 0)\n",
    "    #print(device==\"cuda\")\n",
    "    np_mask = np_mask.to(device)\n",
    "    return np_mask\n",
    "\n",
    "def create_masks(trg):\n",
    "    \n",
    "    trg_mask = (trg != 0).unsqueeze(-2)\n",
    "    #trg_mask.cuda()\n",
    "    size = trg.size(1) # get seq_len for matrix\n",
    "    np_mask = nopeak_mask(size)\n",
    "    np_mask.to(device)\n",
    "    trg_mask = trg_mask & np_mask\n",
    "\n",
    "    return trg_mask\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Training and validation.\n",
    "    \"\"\"\n",
    "\n",
    "    global best_bleu4, epochs_since_improvement, checkpoint, start_epoch, fine_tune_encoder, data_name, word_map\n",
    "\n",
    "    # Read word map\n",
    "    word_map_file = os.path.join(data_folder, 'WORDMAP' + data_name + '.json')\n",
    "    with open(word_map_file, 'r') as j:\n",
    "        word_map = json.load(j)\n",
    "\n",
    "    # Initialize / load checkpoint\n",
    "    \n",
    "    ####checkpoint comment ####\n",
    "    if checkpoint is None:\n",
    "\n",
    "        decoder = Decoder(d_model=decoder_dim, vocab_size=len(word_map), dropout=dropout,)\n",
    "        decoder_optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, decoder.parameters()),\n",
    "                                             lr=decoder_lr)\n",
    "        encoder = Encoder()\n",
    "        encoder_optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, encoder.parameters()),\n",
    "                                             lr=encoder_lr)\n",
    "\n",
    "    else:\n",
    "        checkpoint = torch.load(checkpoint)\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        epochs_since_improvement = checkpoint['epochs_since_improvement']\n",
    "        best_bleu4 = checkpoint['bleu-4']\n",
    "        decoder = checkpoint['decoder']\n",
    "        decoder_optimizer = checkpoint['decoder_optimizer']\n",
    "        encoder = checkpoint['encoder']\n",
    "        encoder_optimizer = checkpoint['encoder_optimizer']\n",
    "        if fine_tune_encoder is True and encoder_optimizer is None:\n",
    "            encoder.fine_tune(fine_tune_encoder)\n",
    "            encoder_optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, encoder.parameters()),\n",
    "                                                 lr=encoder_lr)\n",
    "\n",
    "    # Move to GPU, if available\n",
    "    decoder = decoder.to(device)\n",
    "    encoder = encoder.to(device)\n",
    "\n",
    "    # Loss function\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    # Custom dataloaders\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    print(\"Starting Training..\")\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        CaptionDataset(data_folder, data_name, 'TRAIN', transform=transforms.Compose([normalize])),\n",
    "        batch_size=batch_size, shuffle=True, num_workers=workers, pin_memory=True)\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        CaptionDataset(data_folder, data_name, 'VAL', transform=transforms.Compose([normalize])),\n",
    "        batch_size=batch_size, shuffle=True, num_workers=workers, pin_memory=True)\n",
    "    print(\"Training Complete..\")\n",
    "    # Epochs\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "\n",
    "        # Decay learning rate if there is no improvement for 8 consecutive epochs, and terminate training after 20\n",
    "        if epochs_since_improvement == 20:\n",
    "            break\n",
    "        if epochs_since_improvement > 0 and epochs_since_improvement % 8 == 0:\n",
    "            adjust_learning_rate(decoder_optimizer, 0.8)\n",
    "            if fine_tune_encoder:\n",
    "                adjust_learning_rate(encoder_optimizer, 0.8)\n",
    "\n",
    "        # One epoch's training\n",
    "        train(train_loader=train_loader,\n",
    "              encoder=encoder,\n",
    "              decoder=decoder,\n",
    "              criterion=criterion,\n",
    "              encoder_optimizer=encoder_optimizer,\n",
    "              decoder_optimizer=decoder_optimizer,\n",
    "              epoch=epoch)\n",
    "\n",
    "        # One epoch's validation\n",
    "        recent_bleu4 = validate(val_loader=val_loader,\n",
    "                                encoder=encoder,\n",
    "                                decoder=decoder,\n",
    "                                criterion=criterion)\n",
    "\n",
    "        # Check if there was an improvement\n",
    "        is_best = recent_bleu4 > best_bleu4\n",
    "        best_bleu4 = max(recent_bleu4, best_bleu4)\n",
    "        if not is_best:\n",
    "            epochs_since_improvement += 1\n",
    "            print(\"\\nEpochs since last improvement: %d\\n\" % (epochs_since_improvement,))\n",
    "        else:\n",
    "            epochs_since_improvement = 0\n",
    "\n",
    "        # Save checkpoint\n",
    "        save_checkpoint(data_name, epoch, epochs_since_improvement, encoder, decoder, encoder_optimizer,\n",
    "                        decoder_optimizer, recent_bleu4, is_best)\n",
    "\n",
    "\n",
    "def train(train_loader, encoder, decoder, criterion, encoder_optimizer, decoder_optimizer, epoch):\n",
    "    \"\"\"\n",
    "    Performs one epoch's training.\n",
    "\n",
    "    :param train_loader: DataLoader for training data\n",
    "    :param encoder: encoder model\n",
    "    :param decoder: decoder model\n",
    "    :param criterion: loss layer\n",
    "    :param encoder_optimizer: optimizer to update encoder's weights (if fine-tuning)\n",
    "    :param decoder_optimizer: optimizer to update decoder's weights\n",
    "    :param epoch: epoch number\n",
    "    \"\"\"\n",
    "\n",
    "    decoder.train()  # train mode (dropout and batchnorm is used)\n",
    "    encoder.train()\n",
    "\n",
    "    batch_time = AverageMeter()  # forward prop. + back prop. time\n",
    "    data_time = AverageMeter()  # data loading time\n",
    "    losses = AverageMeter()  # loss (per word decoded)\n",
    "    top5accs = AverageMeter()  # top5 accuracy\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Batches\n",
    "    for i, (imgs, caps, caplens) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - start)\n",
    "\n",
    "        # Move to GPU, if available\n",
    "        imgs = imgs.to(device)\n",
    "        caps = caps.to(device)\n",
    "        caplens = caplens.to(device)\n",
    "        trg_mask = create_masks(caps)\n",
    "\n",
    "        # Forward prop.\n",
    "        imgs = encoder(imgs)\n",
    "        scores, caps_sorted, decode_lengths, sort_ind = decoder(caps, imgs, trg_mask,caplens)\n",
    "\n",
    "        # Since we decoded starting with <start>, the targets are all words after <start>, up to <end>\n",
    "        targets = caps_sorted[:, 1:]\n",
    "\n",
    "        # Remove timesteps that we didn't decode at, or are pads\n",
    "        # pack_padded_sequence is an easy trick to do this\n",
    "        # print(\"the score are shape\",scores.shape ,decode_lengths.shape)\n",
    "        scoresTemp = pack_padded_sequence(scores, decode_lengths, batch_first=True)\n",
    "        scores=scoresTemp.data\n",
    "        targetsTemp = pack_padded_sequence(targets, decode_lengths, batch_first=True)\n",
    "        targets=targetsTemp.data\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(scores, targets)\n",
    "\n",
    "        # Add doubly stochastic attention regularization\n",
    "        ##loss += alpha_c * ((1. - alphas.sum(dim=1)) ** 2).mean()\n",
    "\n",
    "        # Back prop.\n",
    "        decoder_optimizer.zero_grad()\n",
    "        if encoder_optimizer is not None:\n",
    "            encoder_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip gradients\n",
    "        if grad_clip is not None:\n",
    "            clip_gradient(decoder_optimizer, grad_clip)\n",
    "            if encoder_optimizer is not None:\n",
    "                clip_gradient(encoder_optimizer, grad_clip)\n",
    "\n",
    "        # Update weights\n",
    "        decoder_optimizer.step()\n",
    "        if encoder_optimizer is not None:\n",
    "            encoder_optimizer.step()\n",
    "\n",
    "        # Keep track of metrics\n",
    "        top5 = accuracy(scores, targets, 5)\n",
    "        losses.update(loss.item(), sum(decode_lengths))\n",
    "        top5accs.update(top5, sum(decode_lengths))\n",
    "        batch_time.update(time.time() - start)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        # Print status\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Batch Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data Load Time {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Top-5 Accuracy {top5.val:.3f} ({top5.avg:.3f})'.format(epoch, i, len(train_loader),\n",
    "                                                                          batch_time=batch_time,\n",
    "                                                                          data_time=data_time, loss=losses,\n",
    "                                                                          top5=top5accs))\n",
    "\n",
    "def validate(val_loader, encoder, decoder, criterion):\n",
    "    \"\"\"\n",
    "    Performs one epoch's validation.\n",
    "\n",
    "    :param val_loader: DataLoader for validation data.\n",
    "    :param encoder: encoder model\n",
    "    :param decoder: decoder model\n",
    "    :param criterion: loss layer\n",
    "    :return: BLEU-4 score\n",
    "    \"\"\"\n",
    "    decoder.eval()  # eval mode (no dropout or batchnorm)\n",
    "    if encoder is not None:\n",
    "        encoder.eval()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top5accs = AverageMeter()\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    references = list()  # references (true captions) for calculating BLEU-4 score\n",
    "    hypotheses = list()  # hypotheses (predictions)\n",
    "\n",
    "    # explicitly disable gradient calculation to avoid CUDA memory error\n",
    "    # solves the issue #57\n",
    "    with torch.no_grad():\n",
    "        # Batches\n",
    "        for i, (imgs, caps, caplens, allcaps) in enumerate(val_loader):\n",
    "\n",
    "            # Move to device, if available\n",
    "            imgs = imgs.to(device)\n",
    "            caps = caps.to(device)\n",
    "            caplens = caplens.to(device)\n",
    "            trg_mask = create_masks(caps)\n",
    "            # Forward prop.\n",
    "            if encoder is not None:\n",
    "                imgs = encoder(imgs)\n",
    "            scores, caps_sorted, decode_lengths, sort_ind = decoder(caps, imgs, trg_mask,caplens)\n",
    "\n",
    "            # Since we decoded starting with <start>, the targets are all words after <start>, up to <end>\n",
    "            targets = caps_sorted[:, 1:]\n",
    "\n",
    "            # Remove timesteps that we didn't decode at, or are pads\n",
    "            # pack_padded_sequence is an easy trick to do this\n",
    "            scores_copy = scores.clone()\n",
    "            scoresTemp = pack_padded_sequence(scores, decode_lengths, batch_first=True)\n",
    "            scores=scoresTemp.data\n",
    "            targetsTemp = pack_padded_sequence(targets, decode_lengths, batch_first=True)\n",
    "            targets=targetsTemp.data\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(scores, targets)\n",
    "\n",
    "            # Add doubly stochastic attention regularization\n",
    "            ##loss += alpha_c * ((1. - alphas.sum(dim=1)) ** 2).mean()\n",
    "\n",
    "            # Keep track of metrics\n",
    "            losses.update(loss.item(), sum(decode_lengths))\n",
    "            top5 = accuracy(scores, targets, 5)\n",
    "            top5accs.update(top5, sum(decode_lengths))\n",
    "            batch_time.update(time.time() - start)\n",
    "\n",
    "            start = time.time()\n",
    "\n",
    "            if i % print_freq == 0:\n",
    "                print('Validation: [{0}/{1}]\\t'\n",
    "                      'Batch Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'Top-5 Accuracy {top5.val:.3f} ({top5.avg:.3f})\\t'.format(i, len(val_loader), batch_time=batch_time,\n",
    "                                                                                loss=losses, top5=top5accs))\n",
    "                                                               \n",
    "            # Store references (true captions), and hypothesis (prediction) for each image\n",
    "            # If for n images, we have n hypotheses, and references a, b, c... for each image, we need -\n",
    "            # references = [[ref1a, ref1b, ref1c], [ref2a, ref2b], ...], hypotheses = [hyp1, hyp2, ...]\n",
    "\n",
    "            # References\n",
    "            allcaps = allcaps[sort_ind]  # because images were sorted in the decoder\n",
    "            for j in range(allcaps.shape[0]):\n",
    "                img_caps = allcaps[j].tolist()\n",
    "                img_captions = list(\n",
    "                    map(lambda c: [w for w in c if w not in {word_map['<start>'], word_map['<pad>']}],\n",
    "                        img_caps))  # remove <start> and pads\n",
    "                references.append(img_captions)\n",
    "\n",
    "            # Hypotheses\n",
    "            _, preds = torch.max(scores_copy, dim=2)\n",
    "            preds = preds.tolist()\n",
    "            temp_preds = list()\n",
    "            for j, p in enumerate(preds):\n",
    "                temp_preds.append(preds[j][:decode_lengths[j]])  # remove pads\n",
    "            preds = temp_preds\n",
    "            hypotheses.extend(preds)\n",
    "\n",
    "            assert len(references) == len(hypotheses)\n",
    "\n",
    "        # Calculate BLEU-4 scores\n",
    "        chencherry = SmoothingFunction()\n",
    "        bleu4 = corpus_bleu(references, hypotheses ,weights=(1,0,0,0),smoothing_function=chencherry.method4)\n",
    "\n",
    "        print(\n",
    "            '\\n * LOSS - {loss.avg:.3f}, TOP-5 ACCURACY - {top5.avg:.3f}, BLEU-4 - {bleu}\\n'.format(\n",
    "                loss=losses,\n",
    "                top5=top5accs,\n",
    "                bleu=bleu4)) \n",
    "    return bleu4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.17 GiB total capacity; 0 bytes already allocated; 6.94 MiB free; 0 bytes cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c7bc734e5e35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-eb9a436c8f18>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mstart_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mepochs_since_improvement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs_since_improvement'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    535\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_torch_load_uninitialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m                 \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mview_metadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mstorage_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mstorage_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.17 GiB total capacity; 0 bytes already allocated; 6.94 MiB free; 0 bytes cached)"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:33: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 14, 14, 512])\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1],\n",
      "        [9343,  153],\n",
      "        [9343,   15]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39],\n",
      "        [9343,    1,    2],\n",
      "        [9343,    1,  108]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57],\n",
      "        [9343,    1,    2,   57],\n",
      "        [9343,    1,  108,   57]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1],\n",
      "        [9343,    1,    2,   57,    1],\n",
      "        [9343,    1,  108,   57,    1]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39],\n",
      "        [9343,    1,    2,   57,    1,   39],\n",
      "        [9343,    1,   39,   57,    1,    2]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57],\n",
      "        [9343,    1,   39,   57,    1,    2,   57],\n",
      "        [9343,    1,    2,   57,    1,   39,   57]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39]],\n",
      "       device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57]],\n",
      "       device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1]],\n",
      "       device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39]],\n",
      "       device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39]],\n",
      "       device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57]],\n",
      "       device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1]],\n",
      "       device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39]],\n",
      "       device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39]],\n",
      "       device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57]],\n",
      "       device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1]],\n",
      "       device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39]],\n",
      "       device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39]],\n",
      "       device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57]],\n",
      "       device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1]],\n",
      "       device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39]],\n",
      "       device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39]], device='cuda:0')\n",
      "The EMbediings starting are torch.Size([3, 1])\n",
      "The Scores are after again\n",
      " torch.Size([3, 9345])\n",
      "Sequence after is tensor([[9343,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57],\n",
      "        [9343,    1,    2,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57],\n",
      "        [9343,    1,   39,   57,    1,    2,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57,    1,   39,   57,    1,   39,   57,    1,   39,\n",
      "           57,    1,   39,   57]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a7d71a16ffd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;31m# Encode, decode with attention and beam search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcaption_image_beam_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'woman.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;31m# Visualize caption and attention of best sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-a7d71a16ffd9>\u001b[0m in \u001b[0;36mcaption_image_beam_search\u001b[0;34m(encoder, decoder, image_path, word_map, adv_word_map, beam_size)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m# print(\"The sequence is\" , seqs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomplete_seqs_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplete_seqs_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m     \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomplete_seqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import json\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import skimage.transform\n",
    "import argparse\n",
    "from scipy.misc import imread, imresize\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def caption_image_beam_search(encoder, decoder, image_path, word_map,adv_word_map, beam_size=3):\n",
    "    \"\"\"\n",
    "    Reads an image and captions it with beam search.\n",
    "\n",
    "    :param encoder: encoder model\n",
    "    :param decoder: decoder model\n",
    "    :param image_path: path to image\n",
    "    :param word_map: word map\n",
    "    :param beam_size: number of sequences to consider at each decode-step\n",
    "    :return: caption, weights for visualization\n",
    "    \"\"\"\n",
    "\n",
    "    k = beam_size\n",
    "    vocab_size = len(word_map)\n",
    "\n",
    "    # Read image and process\n",
    "    img = imread(image_path)\n",
    "    if len(img.shape) == 2:\n",
    "        img = img[:, :, np.newaxis]\n",
    "        img = np.concatenate([img, img, img], axis=2)\n",
    "    img = imresize(img, (256, 256))\n",
    "    img = img.transpose(2, 0, 1)\n",
    "    img = img / 255.\n",
    "    img = torch.FloatTensor(img).to(device)\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    transform = transforms.Compose([normalize])\n",
    "    image = transform(img)  # (3, 256, 256)\n",
    "\n",
    "    # Encode\n",
    "    image = image.unsqueeze(0)  # (1, 3, 256, 256)\n",
    "    encoder_out = encoder(image)  # (1, enc_image_size, enc_image_size, encoder_dim)\n",
    "    enc_image_size = encoder_out.size(1)\n",
    "    encoder_out = encoder_out.view(1, 14, 14, 512)\n",
    "\n",
    "    print(encoder_out.shape)\n",
    "    encoder_dim = encoder_out.size(3)\n",
    "\n",
    "    # Flatten encoding\n",
    "    encoder_out = encoder_out.view(1, -1, encoder_dim)  # (1, num_pixels, encoder_dim)\n",
    "    num_pixels = encoder_out.size(1)\n",
    "\n",
    "    # We'll treat the problem as having a batch size of k\n",
    "    encoder_out = encoder_out.expand(k, num_pixels, encoder_dim)  # (k, num_pixels, encoder_dim)\n",
    "\n",
    "    # Tensor to store top k previous words at each step; now they're just <start>\n",
    "    k_prev_words = torch.LongTensor([[word_map['<start>']]] * k).to(device)  # (k, 1)\n",
    "\n",
    "    # Tensor to store top k sequences; now they're just <start>\n",
    "    seqs = k_prev_words  # (k, 1)\n",
    "\n",
    "    # Tensor to store top k sequences' scores; now they're just 0\n",
    "    top_k_scores = torch.zeros(k, 1).to(device)  # (k, 1)\n",
    "\n",
    "    # Tensor to store top k sequences' alphas; now they're just 1s\n",
    "\n",
    "    # Lists to store completed sequences, their alphas and scores\n",
    "    complete_seqs = list()\n",
    "    complete_seqs_scores = list()\n",
    "\n",
    "    # Start decoding\n",
    "    step = 1\n",
    "    # h, c = decoder.init_hidden_state(encoder_out)\n",
    "\n",
    "    # s is a number less than or equal to k, because sequences are removed from this process once they hit <end>\n",
    "    while True:\n",
    "        print(\"The EMbediings starting are\", k_prev_words.shape)\n",
    "\n",
    "        embeddings = decoder.embed(k_prev_words)  # (s, embed_dim)\n",
    "        # print(\"The EMbediings are\", embeddings.shape)\n",
    "        embeddings =  decoder.pe(embeddings)\n",
    "        # print(\"The Positional embeddings are\", embeddings.shape)\n",
    "        for i in range(6):\n",
    "            embeddings = decoder.layers[i](embeddings, encoder_out, trg_mask = None)\n",
    "        y = decoder.norm(embeddings)\n",
    "        # print(\"The Outputs are\", y.shape)\n",
    "        results = decoder.out(y)\n",
    "        # print(\"The Outputs are\", results.shape)\n",
    "\n",
    "        #print(\"results is\",F.softmax(results, dim=2), (F.softmax(results, dim=2)).shape)\n",
    "        #scores = torch.argmax(F.softmax(results, dim=2),dim=2)\n",
    "        scores=results.squeeze(1)\n",
    "        \n",
    "\n",
    "        # Add\n",
    "        scores = scores.float()\n",
    "        scores = top_k_scores.expand_as(scores) + scores  # (s, vocab_size)\n",
    "        print(\"The Scores are after again\\n\", scores.shape)\n",
    "\n",
    "        # For the first step, all k points will have the same scores (since same k previous words, h, c)\n",
    "        if step == 1:\n",
    "            top_k_scores, top_k_words = scores[0].topk(k, 0, True, True)  # (s)\n",
    "        else:\n",
    "            # Unroll and find top scores, and their unrolled indices\n",
    "            top_k_scores, top_k_words = scores.view(-1).topk(k, 0, True, True)  # (s)\n",
    "\n",
    "        # Convert unrolled indices to actual indices of scores\n",
    "        prev_word_inds = top_k_words / vocab_size  # (s)\n",
    "        next_word_inds = top_k_words % vocab_size  # (s)\n",
    "        # Add new words to sequences, alphas\n",
    "        seqs = torch.cat([seqs[prev_word_inds], next_word_inds.unsqueeze(1)], dim=1)  # (s, step+1)\n",
    "\n",
    "        # Which sequences are incomplete (didn't reach <end>)?\n",
    "        incomplete_inds = [ind for ind, next_word in enumerate(next_word_inds) if\n",
    "                           next_word != word_map['<end>']]\n",
    "        complete_inds = list(set(range(len(next_word_inds))) - set(incomplete_inds))\n",
    "        # print(\"The indices are after again\", incomplete_inds)\n",
    "\n",
    "        # Set aside complete sequences\n",
    "        if len(complete_inds) > 0 or step==50:\n",
    "            complete_seqs.extend(seqs[complete_inds].tolist())\n",
    "            complete_seqs_scores.extend(top_k_scores[complete_inds])\n",
    "        k -= len(complete_inds)  # reduce beam length accordingly\n",
    "        print(\"Sequence after is\",seqs)\n",
    "\n",
    "        # Proceed with incomplete sequences\n",
    "        if k == 0:\n",
    "            break\n",
    "        # print(\"The seqs are at the end\", seqs.shape)\n",
    "        seqs = seqs[incomplete_inds]\n",
    "        # print(\"The seqs are after the end\", seqs.shape)\n",
    "        # h = h[prev_word_inds[incomplete_inds]]\n",
    "        # c = c[prev_word_inds[incomplete_inds]]\n",
    "        encoder_out = encoder_out[prev_word_inds[incomplete_inds]]\n",
    "        # print(\"the top k scores\",top_k_scores.shape)\n",
    "        top_k_scores = top_k_scores[incomplete_inds].unsqueeze(1)\n",
    "        # print(\"the top k scores are\",top_k_scores.shape)\n",
    "        k_prev_words = next_word_inds[incomplete_inds].unsqueeze(1)\n",
    "\n",
    "        # Break if things have been going on too long\n",
    "        if step > 50:\n",
    "            break\n",
    "        step += 1\n",
    "        # print(\"The sequence is\" , seqs)\n",
    "\n",
    "    i = complete_seqs_scores.index(max(complete_seqs_scores))\n",
    "    seq = complete_seqs[i]\n",
    "    return seq\n",
    "\n",
    "\n",
    "def visualize_att(image_path, seq, alphas, rev_word_map, smooth=True):\n",
    "    \"\"\"\n",
    "    Visualizes caption with weights at every word.\n",
    "\n",
    "    Adapted from paper authors' repo: https://github.com/kelvinxu/arctic-captions/blob/master/alpha_visualization.ipynb\n",
    "\n",
    "    :param image_path: path to image that has been captioned\n",
    "    :param seq: caption\n",
    "    :param alphas: weights\n",
    "    :param rev_word_map: reverse word mapping, i.e. ix2word\n",
    "    :param smooth: smooth weights?\n",
    "    \"\"\"\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize([14 * 24, 14 * 24], Image.LANCZOS)\n",
    "\n",
    "    words = [rev_word_map[ind] for ind in seq]\n",
    "\n",
    "    for t in range(len(words)):\n",
    "        if t > 50:\n",
    "            break\n",
    "        plt.subplot(np.ceil(len(words) / 5.), 5, t + 1)\n",
    "\n",
    "        plt.text(0, 1, '%s' % (words[t]), color='black', backgroundcolor='white', fontsize=12)\n",
    "        plt.imshow(image)\n",
    "        current_alpha = alphas[t, :]\n",
    "        if smooth:\n",
    "            alpha = skimage.transform.pyramid_expand(current_alpha.numpy(), upscale=24, sigma=8)\n",
    "        else:\n",
    "            alpha = skimage.transform.resize(current_alpha.numpy(), [14 * 24, 14 * 24])\n",
    "        if t == 0:\n",
    "            plt.imshow(alpha, alpha=0)\n",
    "        else:\n",
    "            plt.imshow(alpha, alpha=0.8)\n",
    "        plt.set_cmap(cm.Greys_r)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Show, Attend, and Tell - Tutorial - Generate Caption')\n",
    "\n",
    "    # parser.add_argument('--img', '-i', help='path to image')\n",
    "    # parser.add_argument('--model', '-m', help='path to model')\n",
    "    # parser.add_argument('--word_map', '-wm', help='path to word map JSON')\n",
    "    parser.add_argument('--beam_size', '-b', default=5, type=int, help='beam size for beam search')\n",
    "    parser.add_argument('--dont_smooth', dest='smooth', action='store_false', help='do not smooth alpha overlay')\n",
    "\n",
    "    args = Map()\n",
    "    args['beam_size']=5\n",
    "    args['dont_smooth']=True\n",
    "\n",
    "    # Load model\n",
    "    checkpoint = torch.load('BEST_checkpoint__GLOSYS_resnet.pth.tar')\n",
    "    decoder = checkpoint['decoder']\n",
    "    decoder = decoder.to(device)\n",
    "    decoder.eval()\n",
    "    encoder = checkpoint['encoder']\n",
    "    encoder = encoder.to(device)\n",
    "    encoder.eval()\n",
    "\n",
    "    # Load word map (word2ix)\n",
    "    with open('WORDMAP_GLOSYS.json', 'r') as j:\n",
    "        word_map = json.load(j)\n",
    "    rev_word_map = {v: k for k, v in word_map.items()}  # ix2word\n",
    "\n",
    "    # Encode, decode with attention and beam search\n",
    "    seq = caption_image_beam_search(encoder, decoder, 'woman.jpg', word_map, args.beam_size)\n",
    "\n",
    "    # Visualize caption and attention of best sequence\n",
    "    ##visualize_att(args.img, seq, alphas, rev_word_map,word_map, args.smooth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Map(dict):\n",
    "    \"\"\"\n",
    "    Example:\n",
    "    m = Map({'first_name': 'Eduardo'}, last_name='Pool', age=24, sports=['Soccer'])\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Map, self).__init__(*args, **kwargs)\n",
    "        for arg in args:\n",
    "            if isinstance(arg, dict):\n",
    "                for k, v in arg.iteritems():\n",
    "                    self[k] = v\n",
    "\n",
    "        if kwargs:\n",
    "            for k, v in kwargs.iteritems():\n",
    "                self[k] = v\n",
    "\n",
    "    def __getattr__(self, attr):\n",
    "        return self.get(attr)\n",
    "\n",
    "    def __setattr__(self, key, value):\n",
    "        self.__setitem__(key, value)\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        super(Map, self).__setitem__(key, value)\n",
    "        self.__dict__.update({key: value})\n",
    "\n",
    "    def __delattr__(self, item):\n",
    "        self.__delitem__(item)\n",
    "\n",
    "    def __delitem__(self, key):\n",
    "        super(Map, self).__delitem__(key)\n",
    "        del self.__dict__[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
